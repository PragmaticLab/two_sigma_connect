{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Sigma Connect - Rental Listing Inqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kaggle link](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Base dependencies\n",
    "import feather # may need to put this in your .bashrc: export MACOSX_DEPLOYMENT_TARGET=10.10\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "\n",
    "# Machine learning / stats dependencies\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Image processing dependencies\n",
    "from PIL import Image\n",
    "from StringIO import StringIO\n",
    "\n",
    "# Suppress annoying deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../data/\")\n",
    "train_df = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "### What problem are we trying solve?\n",
    "* RentHop is an apartment search website. We are trying to predict the interest level (high, medium, low) of a new listing.\n",
    "* RentHop could use the model developed in this exercise to improve the quality of search results and therefore increase the frequency of bookings.\n",
    "* In addition, our analytic might help RentHop better handle fraud control, identify potential listing quality issues, and allow owners and agents to better understand rentersâ€™ needs and preferences.\n",
    "\n",
    "### What are the relevant metrics? How much do we plan to improve them?\n",
    "* The evaluation metric is the multiclass loss, essentially logloss for 3 interest levels.\n",
    "* A baseline prediction of 0.33 for each class will result in a loss of 1.1. We plan on reducing the logloss to 0.7 or lower (or a prediction of 0.5 for the correct class, an almost 50% increase in confidence from the baseline prediction)\n",
    "\n",
    "### What will we deliver?\n",
    "* A categorical response prediction model for predicting the interest level of an apartment listing.\n",
    "* This prediction will primarily be used to rank apartments from the RentHop search page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "### What are the raw data sources?\n",
    "* The training data provided are raw listing details, provided in JSON format by RentHop.\n",
    "\n",
    "### What does each 'unit' (e.g. row) of data represent?\n",
    "* Each row is an apartment listing, containing internal apartment characteristics (like number of bathrooms) and contextual metadata (like lat-lon and street address)\n",
    "\n",
    "### What are the fields (columns)?\n",
    "* Dependent variable: \n",
    "    - *interest_level (categorical)*: 'High', 'Medium', or 'Low' rental interest, calculated by RentHop using an algorithm undisclosed to the public\n",
    "* Independent variable: \n",
    "    - *bathrooms (numeric)*: Number of bathrooms in the unit\n",
    "    - *bedrooms (numeric)*: Number of bedrooms in the unit\n",
    "    - *building_id (categorical)*: Unique ID for particular building\n",
    "    - *created (date_string)*: Date the listing was first created on RentHop\n",
    "    - *description (string)*: Open-text description of the unit, provided by the listing author\n",
    "    - *display_address (string)*: Marketing-friendly address (not strictly a Post Office address) like \"Studio at 5528-5532 S. Everett Avenue\"\n",
    "    - *features (string)*: Semi-structured list of features like \"gas stove\" and \"air conditioning\"\n",
    "    - *latitude (numeric)*: Latitude of the listed property\n",
    "    - *longitude (numeric)*: Longitude of the listed property\n",
    "    - *listing_id (categorical)*: Unique ID for a particular listing\n",
    "    - *manager_id (categorical)*: Unique ID for a building manager\n",
    "    - *photos (list of strings)*: List of URLs to listing photos on RentHop\n",
    "    - *price (numeric)*: Monthly rent price (in USD)\n",
    "    - *street_address (string)*: Actual street address of the listed property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'bathrooms', u'bedrooms', u'building_id', u'created', u'description',\n",
       "       u'display_address', u'features', u'interest_level', u'latitude',\n",
       "       u'listing_id', u'longitude', u'manager_id', u'photos', u'price',\n",
       "       u'street_address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "* Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_df.isnull().any(axis=1)) # there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distribution of target\n",
    "    * There are about 70% low interest, 23% medium interest and 8% high interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw counts of targets: \n",
      "low       34284\n",
      "medium    11229\n",
      "high       3839\n",
      "Name: interest_level, dtype: int64\n",
      "\n",
      "\n",
      "percentages for targets: \n",
      "low       69.468309\n",
      "medium    22.752877\n",
      "high       7.778813\n",
      "Name: interest_level, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print \"raw counts of targets: \"\n",
    "print train_df.interest_level.value_counts()\n",
    "\n",
    "print \"\\n\\npercentages for targets: \"\n",
    "print train_df.interest_level.value_counts() * 100.0 / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distribution of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### What steps are taken to prepare the data for modeling?\n",
    "* feature transformations? engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the target into one-hot encoding\n",
    "* Interest level (e.g. High, Medium, Low) to One-Hot (e.g. 1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Features from the Apartment Listing Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing description Numerical features\n",
    "* Number of photos\n",
    "* Number of features (features are the tags provided by the listing, e.g. Doorman, Elevator, Fitness Center..etc)\n",
    "* Number of words in description\n",
    "* Year created\n",
    "* Month created\n",
    "* Day created\n",
    "* Hour creaed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)r\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Features Derived from Listing Images\n",
    "\n",
    "We use Python's PIL library to process the provided image files into numeric matrices. Each pixel in the provided image is encoded as a 3-element tuple representing RGB (red, green, blue) values. Each color's value is referred to as a \"channel\" in the image processing literature and in this report\n",
    "\n",
    "* Mean pixel value, red channel\n",
    "* Mean pixel value, green channel\n",
    "* Mean pixel value, blue channel\n",
    "* Standard deviation of pixel values, red channel\n",
    "* Standard deviation of pixel values, green channel\n",
    "* Standard deviation of pixel values, blue channel\n",
    "* Image resolution (total number of pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define helper functions for creating image features\n",
    "def parallelize_dataframe(df, func):\n",
    "    num_partitions = 250 #number of partitions to split dataframe\n",
    "    num_cores = 7 #number of cores on your machine\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def append_image_features(data):\n",
    "    img_features = data['photos'].map(lambda photo_album: get_image_features(photo_album))\n",
    "    img_df = pd.DataFrame({\n",
    "            'mean_red': np.array([feature_dict['mean_red'] for feature_dict in img_features]),\n",
    "            'mean_green': np.array([feature_dict['mean_green'] for feature_dict in img_features]),\n",
    "            'mean_blue': np.array([feature_dict['mean_blue'] for feature_dict in img_features]),\n",
    "            'std_red': np.array([feature_dict['std_red'] for feature_dict in img_features]),\n",
    "            'std_green': np.array([feature_dict['std_green'] for feature_dict in img_features]),\n",
    "            'std_blue': np.array([feature_dict['std_blue'] for feature_dict in img_features]),\n",
    "            'img_resolution': np.array([feature_dict['img_resolution'] for feature_dict in img_features])\n",
    "        })\n",
    "    return img_df\n",
    "\n",
    "def get_image_features(photo_url_list):\n",
    "    \"\"\"\n",
    "    Create one row of features for a collection of\n",
    "    images.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Write a temp file to disk to track progress\n",
    "    fname = '/Users/jlamb/repos/sandbox/tmp/' + str(uuid.uuid1())\n",
    "    with open(fname, 'w') as f:\n",
    "        f.write('x')\n",
    "    \n",
    "    if len(photo_url_list) > 0:\n",
    "        \n",
    "        try: \n",
    "            # Set up collectors\n",
    "            mean_red = []\n",
    "            mean_green = []\n",
    "            mean_blue = []\n",
    "            std_red = []\n",
    "            std_green = []\n",
    "            std_blue = []\n",
    "            img_resolution = []\n",
    "\n",
    "            # TESTING: Just use first image for now\n",
    "            photo_url_list = [photo_url_list[0]]\n",
    "            for url in photo_url_list:\n",
    "\n",
    "                # Get photo (http://stackoverflow.com/questions/7391945/how-do-i-read-image-data-from-a-url-in-python)\n",
    "                url = url\n",
    "                response = requests.get(url)\n",
    "                img = np.array(Image.open(StringIO(response.content)))\n",
    "\n",
    "                # Mean value by channel\n",
    "                mean_red.append(img[:,0].mean())\n",
    "                mean_green.append(img[:,1].mean())\n",
    "                mean_blue.append(img[:,2].mean())\n",
    "\n",
    "                # standard deviation by channel\n",
    "                std_red.append(img[:,0].std())\n",
    "                std_green.append(img[:,1].std())\n",
    "                std_blue.append(img[:,2].std())\n",
    "\n",
    "                # resolution (num pixels)\n",
    "                img_resolution.append(img.size)\n",
    "\n",
    "            # Summarize \n",
    "            out_dict = {\n",
    "                'mean_red': np.mean(np.array(mean_red)),\n",
    "                'mean_green': np.mean(np.array(mean_green)),\n",
    "                'mean_blue': np.mean(np.array(mean_blue)),\n",
    "                'std_red': np.mean(np.array(std_red)),\n",
    "                'std_green': np.mean(np.array(std_green)),\n",
    "                'std_blue': np.mean(np.array(std_blue)),\n",
    "                'img_resolution': np.mean(np.array(img_resolution))\n",
    "            }\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            out_dict = {\n",
    "                'mean_red': float('nan'),\n",
    "                'mean_green': float('nan'),\n",
    "                'mean_blue': float('nan'),\n",
    "                'std_red': float('nan'),\n",
    "                'std_green': float('nan'),\n",
    "                'std_blue': float('nan'),\n",
    "                'img_resolution': float('nan')\n",
    "            }\n",
    "            \n",
    "        \n",
    "    else:\n",
    "    \n",
    "        out_dict = {\n",
    "            'mean_red': float('nan'),\n",
    "            'mean_green': float('nan'),\n",
    "            'mean_blue': float('nan'),\n",
    "            'std_red': float('nan'),\n",
    "            'std_green': float('nan'),\n",
    "            'std_blue': float('nan'),\n",
    "            'img_resolution': float('nan')\n",
    "        }\n",
    "        \n",
    "    return(out_dict)\n",
    "\n",
    "# Apply the image processing or readin cached features\n",
    "if not os.path.isfile('img_df.feather'):\n",
    "    img_df = parallelize_dataframe(train_df, append_image_features)\n",
    "    feather.write_dataframe(img_df, 'img_df.feather')\n",
    "else:\n",
    "    img_df = feather.read_dataframe('img_df.feather')\n",
    "\n",
    "# Append image features to train_df (equivalent to R 'cbind')\n",
    "train_df = pd.concat([train_df.reset_index(), img_df.reset_index()], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precise description of modeling base tables.\n",
    "* What are the rows/columns of X (the predictors)?\n",
    "* Target variable:\n",
    "    - *interest_level (categorical)*: A three-level categorical variable. Encoded as 0, 1, 2 corresponding with levels \"low\", \"medium\" and \"high\" interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "### What model are we using? Why?\n",
    "### Assumptions?\n",
    "### Regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "### How well does the model perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "Implementing a deployed analytic is outside the scope of this exercise. The answers below are hypothetical only.\n",
    "\n",
    "### How is the model deployed?\n",
    "* To be deployed at RentHop, it's likely that the model would need to be deployed as a standalone microservice which can be managed by Operational personnell. Regardless of the exact technology used, the application should expect to receive a JSON payload with raw listing details and should produce a small JSON objects with probabilities for each class ('low', 'medium', 'high'). We see a few possible configurations that could support such an app:\n",
    "    1. All-Python app (e.g. Flask) listening for POST requests with listing data\n",
    "    2. Containerized Python app (e.g. in Docker) in a container which also runs a web server\n",
    "    3. Python model rewritten in Java by engineers\n",
    "\n",
    "### What support is provided after initial deployment?\n",
    "* Model results will be tracked by nightly batch jobs to try to catch eroding environmental fit\n",
    "* The model may need to be updated periodically to refelect a changing renatl environment or to incorporate new data sources"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (twosigma)",
   "language": "python",
   "name": "twosigma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

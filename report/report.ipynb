{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Sigma Connect - Rental Listing Inqueries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kaggle link](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../data/\")\n",
    "train_df = pd.read_json(\"train.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "### What problem are we trying solve?\n",
    "* RentHop is an apartment search website. We are trying to predict the interest level (high, medium, low) of a new listing. \n",
    "* This will help RentHop better handle fraud control, identify potential listing quality issues, and allow owners and agents to better understand rentersâ€™ needs and preferences.\n",
    "\n",
    "### What are the relevant metrics? How much do we plan to improve them?\n",
    "* The evaluation metric is the multiclass loss, essentially logloss for 3 interest levels.\n",
    "* A baseline prediction of 0.33 for each class will result in a loss of 1.1. We plan on reducing the logloss to 0.7 or lower (or a prediction of 0.5 for the correct class, an almost 50% increase in confidence from the baseline prediction)\n",
    "\n",
    "### What will we deliver?\n",
    "* A categorical response prediction model for predicting the interest level of an apartment listing.\n",
    "* This prediction will primarily be used to rank apartments from the RentHop search page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "### What are the raw data sources?\n",
    "* The data source is the train.json file\n",
    "\n",
    "### What does each 'unit' (e.g. row) of data represent?\n",
    "* Each row is an apartment listing\n",
    "\n",
    "### What are the fields (columns)?\n",
    "* Dependent variable: interest_level\n",
    "* Independent variable: bathrooms, bedrooms, building_id, created, description, display_address, features, latitude, longitude, listing_id, manager_id, photos, price, street_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'bathrooms', u'bedrooms', u'building_id', u'created', u'description',\n",
       "       u'display_address', u'features', u'interest_level', u'latitude',\n",
       "       u'listing_id', u'longitude', u'manager_id', u'photos', u'price',\n",
       "       u'street_address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "* Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_df.isnull().any(axis=1)) # there are no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distribution of target\n",
    "    * There are about 70% low interest, 23% medium interest and 8% low interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw counts of targets: \n",
      "low       34284\n",
      "medium    11229\n",
      "high       3839\n",
      "Name: interest_level, dtype: int64\n",
      "\n",
      "\n",
      "percentages for targets: \n",
      "low       69.468309\n",
      "medium    22.752877\n",
      "high       7.778813\n",
      "Name: interest_level, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print \"raw counts of targets: \"\n",
    "print train_df.interest_level.value_counts()\n",
    "\n",
    "print \"\\n\\npercentages for targets: \"\n",
    "print train_df.interest_level.value_counts() * 100.0 / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distribution of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Relationships between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### What steps are taken to prepare the data for modeling?\n",
    "* feature transformations? engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the target into one-hot encoding\n",
    "* Interest level (e.g. High, Medium, Low) to One-Hot (e.g. 1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_num_map = {'high':0, 'medium':1, 'low':2}\n",
    "y = np.array(train_df['interest_level'].apply(lambda x: target_num_map[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Features from the Apartment Listing Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing description Numerical features\n",
    "* Number of photos\n",
    "* Number of features (features are the tags provided by the listing, e.g. Doorman, Elevator, Fitness Center..etc)\n",
    "* Number of words in description\n",
    "* Year created\n",
    "* Month created\n",
    "* Day created\n",
    "* Hour creaed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)r\n",
    "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
    "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
    "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
    "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
    "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
    "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
    "train_df[\"created_hour\"] = train_df[\"created\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precise description of modeling base tables.\n",
    "* What are the rows/columns of X (the predictors)?\n",
    "* What is y (the target)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "### What model are we using? Why?\n",
    "### Assumptions?\n",
    "### Regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "### How well does the model perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "\n",
    "### How is the model deployed?\n",
    "* The model will be deployed via a python-based API server.\n",
    "* The requests will contain all the necessary covariates, and the API will respond with predictions for each different interest level.\n",
    "\n",
    "### What support is provided after initial deployment?\n",
    "* The model will be updated nightly to provide the most up to date predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
